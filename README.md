# X√ÇY D·ª∞NG H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN C·ª¨ CH·ªà TAY H·ªñ TR·ª¢ NG∆Ø·ªúI KHUY·∫æT T·∫¨T GIAO TI·∫æP

<p align="center">
  <img src="logoDaiNam.png" alt="DaiNam University Logo" width="200"/>
  <img src="LogoAIoTLab.png" alt="AIoTLab Logo" width="170"/>
</p>

[![Made by AIoTLab](https://img.shields.io/badge/Made%20by%20AIoTLab-blue?style=for-the-badge)](https://www.facebook.com/DNUAIoTLab)
[![Fit DNU](https://img.shields.io/badge/Fit%20DNU-green?style=for-the-badge)](https://fitdnu.net/)
[![DaiNam University](https://img.shields.io/badge/DaiNam%20University-red?style=for-the-badge)](https://dainam.edu.vn)

## üåü Gi·ªõi thi·ªáu

Ng∆∞·ªùi khuy·∫øt t·∫≠t v·ªÅ nghe v√† n√≥i g·∫∑p nhi·ªÅu kh√≥ khƒÉn trong giao ti·∫øp v·ªõi c·ªông ƒë·ªìng. Ng√¥n ng·ªØ k√Ω hi·ªáu l√† ph∆∞∆°ng ti·ªán giao ti·∫øp ch√≠nh c·ªßa h·ªç, nh∆∞ng kh√¥ng ph·∫£i ai c≈©ng hi·ªÉu ƒë∆∞·ª£c. V√¨ v·∫≠y, vi·ªác x√¢y d·ª±ng m·ªôt h·ªá th·ªëng nh·∫≠n di·ªán c·ª≠ ch·ªâ tay gi√∫p chuy·ªÉn ƒë·ªïi ng√¥n ng·ªØ k√Ω hi·ªáu th√†nh vƒÉn b·∫£n ho·∫∑c gi·ªçng n√≥i l√† r·∫•t c·∫ßn thi·∫øt.

V·ªõi s·ª± ph√°t tri·ªÉn c·ªßa tr√≠ tu·ªá nh√¢n t·∫°o (AI) v√† th·ªã gi√°c m√°y t√≠nh, ƒë·ªÅ t√†i n√†y t·∫≠p trung nghi√™n c·ª©u v√† ·ª©ng d·ª•ng c√°c m√¥ h√¨nh h·ªçc s√¢u ƒë·ªÉ nh·∫≠n di·ªán c·ª≠ ch·ªâ tay, gi√∫p ng∆∞·ªùi khuy·∫øt t·∫≠t giao ti·∫øp thu·∫≠n ti·ªán h∆°n. H·ªá th·ªëng kh√¥ng ch·ªâ h·ªó tr·ª£ c√° nh√¢n m√† c√≤n g√≥p ph·∫ßn t·∫°o ra m·ªôt m√¥i tr∆∞·ªùng giao ti·∫øp th√¢n thi·ªán, h√≤a nh·∫≠p h∆°n cho c·ªông ƒë·ªìng.

## üõ†Ô∏è Ch·ª©c nƒÉng ch√≠nh

- **Chu·∫©n b·ªã d·ªØ li·ªáu:** T·∫£i b·ªô d·ªØ li·ªáu ASL Alphabet t·ª´ Kaggle, gi·∫£i n√©n v√† s·∫Øp x·∫øp d·ªØ li·ªáu theo t·ª´ng l·ªõp k√Ω hi·ªáu.
- **Hu·∫•n luy·ªán m√¥ h√¨nh:** H·ªó tr·ª£ c√°c m√¥ h√¨nh CNN, Xception ƒë·ªÉ nh·∫≠n di·ªán c·ª≠ ch·ªâ tay. Theo d√µi qu√° tr√¨nh h·ªçc qua bi·ªÉu ƒë·ªì v√† ma tr·∫≠n nh·∫ßm l·∫´n.
- **Nh·∫≠n di·ªán t·ª´ ·∫£nh:** Cung c·∫•p m·ªôt ·∫£nh ch·ª©a c·ª≠ ch·ªâ tay. H·ªá th·ªëng hi·ªÉn th·ªã ·∫£nh v√† d·ª± ƒëo√°n k√Ω hi·ªáu.
- **Nh·∫≠n di·ªán t·ª´ video:** T·∫£i l√™n video c√≥ ch·ª©a c·ª≠ ch·ªâ tay. H·ªá th·ªëng t√°ch khung h√¨nh v√† d·ª± ƒëo√°n t·ª´ng c·ª≠ ch·ªâ.
- **Chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i:** Sau khi nh·∫≠n di·ªán, h·ªá th·ªëng ph√°t √¢m thanh t∆∞∆°ng ·ª©ng v·ªõi k√Ω hi·ªáu.
- **L∆∞u v√† s·ª≠ d·ª•ng l·∫°i m√¥ h√¨nh:** M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u l·∫°i ƒë·ªÉ s·ª≠ d·ª•ng sau m√† kh√¥ng c·∫ßn hu·∫•n luy·ªán l·∫°i.

## üñ•Ô∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng

H·ªá th·ªëng n√†y ƒë∆∞·ª£c x√¢y d·ª±ng v·ªõi c√°c c√¥ng ngh·ªá v√† th∆∞ vi·ªán sau:

### Tr√≠ tu·ªá nh√¢n t·∫°o (AI) & H·ªçc s√¢u (Deep Learning)
- **TensorFlow & Keras:** Hu·∫•n luy·ªán v√† tri·ªÉn khai m√¥ h√¨nh nh·∫≠n di·ªán c·ª≠ ch·ªâ tay.
- **M√¥ h√¨nh CNN & Xception:** D√πng ƒë·ªÉ h·ªçc ƒë·∫∑c tr∆∞ng t·ª´ h√¨nh ·∫£nh c·ª≠ ch·ªâ tay.
- **Scikit-learn:** H·ªó tr·ª£ ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v√† ƒë√°nh gi√° m√¥ h√¨nh.

### Th·ªã gi√°c m√°y t√≠nh (Computer Vision)
- **OpenCV:** X·ª≠ l√Ω h√¨nh ·∫£nh v√† video ƒë·ªÉ ph√°t hi·ªán v√† nh·∫≠n di·ªán c·ª≠ ch·ªâ tay.

### Ph√¢n t√≠ch v√† tr·ª±c quan h√≥a d·ªØ li·ªáu
- **NumPy & Pandas:** X·ª≠ l√Ω v√† qu·∫£n l√Ω d·ªØ li·ªáu.
- **Matplotlib, Seaborn, Plotly:** V·∫Ω bi·ªÉu ƒë·ªì ƒë·ªÉ theo d√µi qu√° tr√¨nh hu·∫•n luy·ªán.
- **M√¥ h√¨nh CNN & Xception:** Hi·ªÉn th·ªã k·∫øt qu·∫£ hu·∫•n luy·ªán v√† d·ª± ƒëo√°n tr·ª±c quan.

### X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP) & T·ªïng h·ª£p gi·ªçng n√≥i
- **gTTS (Google Text-to-Speech):** Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh gi·ªçng n√≥i sau khi nh·∫≠n di·ªán k√Ω hi·ªáu.

### L∆∞u v√† s·ª≠ d·ª•ng l·∫°i m√¥ h√¨nh
- TensorFlow/Keras h·ªó tr·ª£ l∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ s·ª≠ d·ª•ng l·∫°i m√† kh√¥ng c·∫ßn hu·∫•n luy·ªán t·ª´ ƒë·∫ßu.

## üìö D·ªØ li·ªáu s·ª≠ d·ª•ng

D·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng t·ª´ Kaggle:
- **B·ªô d·ªØ li·ªáu ASL Alphabet:** [T·∫£i t·∫°i ƒë√¢y](https://www.kaggle.com/datasets/grassknoted/asl-alphabet)
- Sau khi t·∫£i, gi·∫£i n√©n v√† s·∫Øp x·∫øp v√†o th∆∞ m·ª•c ph√π h·ª£p.

## üìö C√°c th∆∞ vi·ªán Python c·∫ßn thi·∫øt

C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán b·∫±ng l·ªánh sau:
```sh
pip install opencv-python tensorflow keras numpy pandas scikit-learn matplotlib seaborn plotly gtts
```

## ‚öôÔ∏è Y√™u c·∫ßu h·ªá th·ªëng

### Ch·∫°y tr√™n Google Colab
H·ªá th·ªëng c√≥ th·ªÉ ch·∫°y tr√™n Google Colab m√† kh√¥ng c·∫ßn c·∫•u h√¨nh ph·ª©c t·∫°p. Ch·ªâ c·∫ßn t·∫£i notebook l√™n v√† ch·∫°y c√°c √¥ l·ªánh theo th·ª© t·ª±.

#### H∆∞·ªõng d·∫´n ch·∫°y tr√™n Google Colab:
1. **T·∫£i notebook l√™n Colab:** M·ªü [Google Colab](https://colab.research.google.com/drive/1168Y2dzgFTMZHrBGYqPZRC3TRRziJFbn?usp=sharing#scrollTo=XMNa-EjUUeR3).
2. **C√†i ƒë·∫∑t th∆∞ vi·ªán:** Ch·∫°y √¥ l·ªánh sau trong Colab ƒë·ªÉ c√†i ƒë·∫∑t th∆∞ vi·ªán:
   ```python
   !pip install opencv-python tensorflow keras numpy pandas scikit-learn matplotlib seaborn plotly gtts
   ```
3. **T·∫£i d·ªØ li·ªáu ASL Alphabet:**
   ```python
   !kaggle datasets download -d grassknoted/asl-alphabet
   !unzip asl-alphabet.zip -d data/
   ```
4. **K·∫øt n·ªëi v·ªõi GPU (t√πy ch·ªçn):** V√†o `Runtime` > `Change runtime type` > Ch·ªçn `GPU` ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô hu·∫•n luy·ªán.
5. **Ch·∫°y t·ª´ng √¥ l·ªánh theo th·ª© t·ª±** trong notebook ƒë·ªÉ hu·∫•n luy·ªán v√† ki·ªÉm tra m√¥ h√¨nh.

### Ch·∫°y tr√™n m√°y t√≠nh c√° nh√¢n (Visual Studio Code)
N·∫øu ch·∫°y tr√™n Visual Studio Code ho·∫∑c m√¥i tr∆∞·ªùng c·ª•c b·ªô:
- **Python 3.7 tr·ªü l√™n**
- **C√†i ƒë·∫∑t ƒë·∫ßy ƒë·ªß th∆∞ vi·ªán c·∫ßn thi·∫øt** (xem m·ª•c "C√°c th∆∞ vi·ªán Python c·∫ßn thi·∫øt")
- **GPU (t√πy ch·ªçn):** N·∫øu c√≥ GPU, c√†i ƒë·∫∑t CUDA ƒë·ªÉ tƒÉng t·ªëc hu·∫•n luy·ªán m√¥ h√¨nh

## üöÄ H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t v√† ch·∫°y ch∆∞∆°ng tr√¨nh

### 1. C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng
N·∫øu ch∆∞a c√≥ Python, h√£y t·∫£i v√† c√†i ƒë·∫∑t Python 3.7 tr·ªü l√™n t·ª´ [python.org](https://www.python.org/).

Sau ƒë√≥, c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt b·∫±ng l·ªánh:
```sh
pip install -r requirements.txt
```
(N·∫øu kh√¥ng c√≥ `requirements.txt`, d√πng l·ªánh `pip install opencv-python tensorflow keras numpy pandas scikit-learn matplotlib seaborn plotly gtts`.)

### 2. Ch·∫°y ch∆∞∆°ng tr√¨nh
#### Tr√™n Google Colab: (D·ª± ƒëo√°n b·∫±ng ·∫£nh v√† video)
- **B∆∞·ªõc 1: T·∫£i Dataset**
- [Link t·∫£i](https://www.kaggle.com/datasets/grassknoted/asl-alphabet)
- **B∆∞·ªõc 2: T·∫£i th∆∞ vi·ªán**
  ```python
  !pip install tensorflow opencv-python gtts scikit-learn seaborn
  ```
- **B∆∞·ªõc 3: G·∫Øn link dataset**
  ```python
  data='/content/asl_data/asl_alphabet_train/asl_alphabet_train'
  ```
- **B∆∞·ªõc 4: Chia ra l√†m 3 ƒë·ªÉ hu·∫•n luy·ªán: 80% train, 10% test, 10% val**
  ```python
  from sklearn.model_selection import train_test_split
  train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 42)
  valid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state= 42)
  ```
- **B∆∞·ªõc 5: X√¢y d·ª±ng m√¥ h√¨nh Xception, CNN v√† hu·∫•n luy·ªán AI**
  ```python
  base_model = tf.keras.applications.xception.Xception(weights= 'imagenet' ,include_top = False , input_shape = (150,150,3) ,pooling = 'max' )
  model = Sequential([
    BatchNormalization(),
    Dense(256,activation = 'relu'),
    Dropout(.5),
    Dense(29 , activation= 'softmax' )
  ])
  model.compile(Adamax(learning_rate = 0.001) , loss = 'categorical_crossentropy' , metrics= ['accuracy'])
  history = model.fit(
    x= train_generator ,
    validation_data= valid_generator ,
    epochs= 5 , verbose = 1 ,
    validation_steps= None, shuffle= False
  )
  ```
- **B∆∞·ªõc 6: T√≠ch h·ª£p Text-to-speech**
  ```python
  !pip install gTTS # install the missing gTTS module
  from gtts import gTTS # import the gTTS module to make it accessible
  from IPython.display import Audio # Import Audio to play the output
  import IPython.display as ipd # import the ipd to be used later
  def text_to_speech(text, lang='en'):
    tts = gTTS(text=text, lang=lang)
    tts.save("output.mp3")
    ipd.display(ipd.Audio("output.mp3", autoplay=True))
  ```
- **B∆∞·ªõc 7: D·ª± ƒëo√°n h√¨nh ·∫£nh**
  ```python
    class_labels = list(train_generator.class_indices.keys())

    def predict_sign(model, img_path):
    # Load v√† x·ª≠ l√Ω ·∫£nh
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (150, 150))
    img = img / 255.0  # Chu·∫©n h√≥a v·ªÅ [0, 1]
    img = np.expand_dims(img, axis=0)  # Th√™m batch dimension
    predictions = model.predict(img)
    predicted_class = np.argmax(predictions)
    confidence = np.max(predictions)
    label = class_labels[predicted_class]
    return label, confidence, img # Return the image as well
    import matplotlib.pyplot as plt
    test_image = '/content/asl_data/asl_alphabet_test/asl_alphabet_test/A_test.jpg'  # ƒê·ªïi path t·ªõi h√¨nh b·∫°n mu·ªën test
    label, confidence, img = predict_sign(model, test_image) # Get the image from the function
    print(f"D·ª± ƒëo√°n: {label}, ƒê·ªô tin c·∫≠y: {confidence:.2f}")
    plt.imshow(img[0]) # Display the image using matplotlib
    plt.title(f"Predicted: {label}")
    plt.axis('off')
    plt.show()
    text_to_speech(label)
  ```
#### Tr√™n Python: (D·ª± ƒëo√°n b·∫±ng Camera)
- **Hu·∫•n luy·ªán m√¥ h√¨nh CNN/Xception:** (Do ƒë√£ c√≥ File hu·∫•n luy·ªán t·ª´ tr∆∞·ªõc c√≥ th·ªÉ b·ªè qua b∆∞·ªõc n√†y)
-  Ch·∫°y File train.py
- **Nh·∫≠n di·ªán c·ª≠ ch·ªâ t·ª´ Camera:**
-  Ch·∫°y File predict.py


### Ph√¢n chia c√¥ng vi·ªác:
  Phong Ng·ªçc Anh (nh√≥m tr∆∞·ªüng): Ph√°t tri·ªÉn to√†n b·ªô m√£ ngu·ªìn, tri·ªÉn khai d·ª± √°n, ƒë·ªÅ xu·∫•t c·∫£i ti·∫øn, ki·∫øm th·ª≠, th·ª±c hi·ªán video gi·ªõi thi·ªáu, thuy·∫øt tr√¨nh, L√†m Power Point, Github
  
  B√πi Trung Qu√¢n: H·ªó tr·ª£ l√†m Power Point, ch·ªânh s·ª≠a Video, Github
  
  V≈© ƒê·ª©c To√†n: Bi√™n so·∫°n t√†i li·ªáu Overleaf


